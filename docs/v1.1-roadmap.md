# MaiChat v1.1 Roadmap

## Vision

Transform MaiChat into a fully competitive multimodal AI interface: add image support and web search while maintaining topic-organized conversations navigated at keystroke speed.

## Current State (v1.0.1)

**Strengths/Features:**
- ✅ Topic-based organization
- ✅ Keyboard-centric navigation
- ✅ Multi-model support (OpenAI, Claude, Gemini)
- ✅ Powerful filtering and context control
- ✅ 100% client-side, privacy-first

## Key architectural contraints. NB! Important!!!
- The app is now in production.
- All changes affecting current modules must be first carefully audited and vetted and they must not interfere with existing functionaliy, unless explicitly discussed and agreed in specs.
- The new features / components must adhere to the existing architecture principles and follow the same architectural patterns with maximum isolation of the components and reuse of the existing code.

## Implementation Sequence

### Phase 1: Grok Integration (Weeks 1-2)

- xAI API integration
- Model catalog (grok-4-fast-reasoning, grok-4-fast-nonreasoning, grok-code-fast-1)
- Request/response handlers with vision + search structure
- Request/response handlers supporting image incorporation into request.
- API key management

**Outcome:** Working Grok with text/images, search capability, payload structure.

---

### Phase 2: Web Search - All Providers (Weeks 3-4)

**Why Now:**
All providers support native search (no external APIs). Build on proven Grok pattern.

**Provider Implementations (in order):**
- **Grok:** Built-in X/Twitter search (already done)
- **Gemini:** Grounding with Google Search (`tools: [{ googleSearch: {} }]`)
- **Anthropic:** Recent API addition (verify payload format)
- **OpenAI:** Migrate to new Response API from the currently used (old) Completions API. Response API natively supports web search (no external tools!)

**UI:**
- Modify Model Catalog to store Search-enabled boolean parameter and include it in Model Editor overlay.
- Citation display in responses

**Technical Scope:**
- Modify: `src/core/providers/openaiProvider.js`
- Modify: `src/core/providers/anthropicProvider.js`
- Modify: `src/core/providers/geminiProvider.js`
- Already done: `src/core/providers/grokProvider.js`
- Update message display for access to citations (sources)

---

### Phase 3: Image Infrastructure (Weeks 5-6)

**Why Now:**
Providers ready. Focus on data flow before UI complexity.

**Primary Use Case:** Screenshots (code, errors, diagrams, UI mockups)

**Technical:**
- **Storage:** IndexedDB (JPEG/PNG, ~5MB limit, 1-5 images/message)
- **Encoding:** Base64 for API transmission
- **Provider Formats:** Update payload builders for vision
- **History:** Image references in message schema
- **Context:** Token calculations including images

**Outcome:** Can programmatically attach and send images to all vision-capable models.

---

### Phase 4: Image UI & Keyboard Workflow (Weeks 7-8)

**Design Challenge:**
Keyboard-based image workflow without compromising "keystroke-fast" operation.

**Keyboard Commands (preliminary, TBD later):**
```
Ctrl+I          Open image attach dialog
Cmd+V           Paste from clipboard
j/k             Navigate attachments
Space           Toggle selection
Enter           Confirm attach
d/x             Remove attachment
Esc             Close dialog
```

**UI Components:**
1. **Input Indicator:** Shows attached images count
2. **Attach Dialog:** File picker with keyboard navigation
3. **History Display:** Inline image thumbnails
4. **Preview Overlay:** Full-size view (keyboard navigation)

**Image Methods:**
- Keyboard dialog (Ctrl+I)
- Clipboard paste (Cmd+V) - primary for screenshots
- Drag-and-drop (mouse fallback)
- File path entry (power users)

